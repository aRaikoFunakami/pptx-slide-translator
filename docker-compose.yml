services:
  pptx-translator:
    build: .
    container_name: pptx-translator
    ports:
      - "80:8000"
    environment:
      # 必須: OpenAI APIキー
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      
      # オプション: モデル設定（デフォルト: gpt-4.1-mini）
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4.1-mini}
      
      # オプション: カスタムAPIエンドポイント（ローカルLLM用）
      - OPENAI_BASEURL=${OPENAI_BASEURL:-}
      
      # オプション: 同時翻訳処理数（デフォルト: 1）
      - MAX_CONCURRENT_TRANSLATIONS=${MAX_CONCURRENT_TRANSLATIONS:-1}
    volumes:
      # ログを永続化
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/queue"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - observability
    labels:
      - "logging=enabled"

  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    command: -config.file=/etc/loki/config.yml
    volumes:
      - ./loki:/etc/loki:ro
      - loki_data:/loki
    ports:
      - "3100:3100"
    restart: unless-stopped
    networks:
      - observability

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=pptx_translator_2025
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    restart: unless-stopped
    networks:
      - observability

  alloy:
    image: grafana/alloy:latest
    container_name: alloy
    volumes:
      - ./alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./logs:/var/log/app:ro
    command: run --server.http.listen-addr=0.0.0.0:12345 /etc/alloy/config.alloy
    ports:
      - "12345:12345"
    restart: unless-stopped
    networks:
      - observability

networks:
  observability:
    driver: bridge

volumes:
  grafana_data: {}
  loki_data: {}